# -*- coding: utf-8 -*-
"""pyspark_job.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AHLRp4Zzc5V9-2aDx0k-dEux4qXK8JiC
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, sum as _sum, desc
from pyspark.ml.feature import VectorAssembler, StringIndexer
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator
import time

print("Initializing Spark Session on VM...")
spark = SparkSession.builder \
    .appName("Team10_Final_Boss") \
    .master("local[*]") \
    .config("spark.driver.memory", "4g") \
    .getOrCreate()

input_path = "csgo_round_snapshots.csv"
print(f"Reading data from: {input_path}")
df = spark.read.csv(input_path, header=True, inferSchema=True)

df_clean = df.withColumn("label", when(col("round_winner") == "CT", 1.0).otherwise(0.0))
df_clean.cache()

print("\n--- Starting Machine Learning Pipeline (Maps + Economy + Live State) ---")

print("Indexing Maps...")

indexer = StringIndexer(inputCol="map", outputCol="map_idx")

indexer_model = indexer.fit(df_clean)
df_indexed = indexer_model.transform(df_clean)

feature_cols = [
    "map_idx",
    "ct_money", "t_money",
    "ct_health", "t_health",
    "ct_armor", "t_armor",
    "ct_helmets", "t_helmets",
    "ct_defuse_kits",
    "ct_players_alive", "t_players_alive",
    "bomb_planted"
]

df_model = df_indexed.select(feature_cols + ["label"]).dropna()

assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
data_final = assembler.transform(df_model)

train_data, test_data = data_final.randomSplit([0.8, 0.2], seed=42)

print("Training Random Forest Model (With Map Bias)...")
rf = RandomForestClassifier(featuresCol="features", labelCol="label", numTrees=50)
rf_model = rf.fit(train_data)

predictions = rf_model.transform(test_data)
evaluator = BinaryClassificationEvaluator()
auc = evaluator.evaluate(predictions)
print(f"Model Training Complete. Area Under ROC: {auc}")

print("\n--- Starting Weapon Meta-Analysis ---")
ct_weapon_cols = [c for c in df.columns if c.startswith("ct_weapon_")]
ct_wins_df = df.filter(col("round_winner") == "CT")
exprs = [_sum(col(c)).alias(c) for c in ct_weapon_cols]
ct_weapon_stats = ct_wins_df.agg(*exprs)

stack_expr = f"stack({len(ct_weapon_cols)}, " + \
             ", ".join([f"'{c}', {c}" for c in ct_weapon_cols]) + \
             ") as (weapon_name, total_count)"

top_weapons = ct_weapon_stats.selectExpr(stack_expr).orderBy(desc("total_count")).limit(5)
top_weapons.show(truncate=False)

print("\n--- Saving Results ---")
output_metrics = "out_metrics"
output_weapons = "out_weapons"

spark.createDataFrame([(auc,)], ["AreaUnderROC"]).coalesce(1).write.csv(output_metrics, mode="overwrite", header=True)
top_weapons.coalesce(1).write.csv(output_weapons, mode="overwrite", header=True)

print("Job Finished. Waiting 30 seconds...")
time.sleep(30)
spark.stop()